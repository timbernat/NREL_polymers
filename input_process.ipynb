{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering expanded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# File I/O\n",
    "from pathlib import Path\n",
    "import csv, json, openpyxl\n",
    "\n",
    "# Typing and Subclassing\n",
    "from typing import Iterable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "\n",
    "# Custom imports\n",
    "from polymerist.rdutils import rdkdraw\n",
    "from polymerist.rdutils.smileslib import queries\n",
    "from polymerist.monomers import specification\n",
    "\n",
    "DIM    = 300\n",
    "ASPECT = 3/2\n",
    "rdkdraw.set_rdkdraw_size(DIM, ASPECT)\n",
    "rdkdraw.disable_substruct_highlights()\n",
    "\n",
    "# Static Paths\n",
    "RAW_DATA_DIR  = Path('monomer_data_raw')\n",
    "FMT_DATA_DIR  = Path('monomer_data_formatted')\n",
    "PROC_DATA_DIR = Path('monomer_data_processed')\n",
    "RXN_FILES_DIR = Path('poly_rxns')\n",
    "# RXN_FILES_DIR = Path('rxn_smarts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading desired dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data_path = FMT_DATA_DIR / 'nipu_urethanes_FMT.csv'\n",
    "input_data_path = FMT_DATA_DIR / '20231114_polyid_data_density_DP2-6 - 1,2 monomers.csv'\n",
    "# input_data_path = FMT_DATA_DIR / '221010_trainingdata_DP-18_expanded_FMT.csv'\n",
    "df = pd.read_csv(input_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining queries for illegal chemistries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illegal_chem_queries = {\n",
    "    'silicon' : Chem.MolFromSmarts('[Si]'),\n",
    "    'sulfur'  : Chem.MolFromSmarts('[S]'),\n",
    "    'metal'   : queries.SPECIAL_QUERY_MOLS['metal'],\n",
    "    # 'halogen' : queries.SPECIAL_QUERY_MOLS['halogen'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and backmapping premade reaction functional groups and templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rxn_backmap = { # map NREL dataset mechanism names to pre-made rxn template names\n",
    "    'amide'     : 'polyamide',\n",
    "    'carbonate' : 'polycarbonate_phosgene',\n",
    "    'ester'     : 'polyester',\n",
    "    'imide'     : 'polyimide',\n",
    "    'urethane'  : 'polyurethane_isocyanate',\n",
    "    'NIPU'      : 'polyurethane_nonisocyanate',\n",
    "    'vinyl'     : 'polyvinyl_head_tail'\n",
    "}\n",
    "assert(set(df['mechanism'].unique()).issubset(set(rxn_backmap.keys()))) # verify that we've mapped all reactions\n",
    "\n",
    "with (RXN_FILES_DIR / 'rxn_backmap.json').open('w') as backmap_file:\n",
    "    json.dump(rxn_backmap, backmap_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (RXN_FILES_DIR / 'fn_group_smarts.json').open('r') as file:\n",
    "    fn_group_smarts  = json.load(file)\n",
    "    \n",
    "fn_group_queries = { # RDKit Mols generated from SMARTS queries\n",
    "    group_name : Chem.MolFromSmarts(smarts)\n",
    "        for group_name, smarts in fn_group_smarts.items()\n",
    "}\n",
    "\n",
    "with (RXN_FILES_DIR / 'rxn_groups.json').open('r') as file: # load table of functional group for each reaction\n",
    "    rxn_groups = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banned_monomers = [ # monomers which are, for one reason or another, disallowed\n",
    "    'CC(C)(C)c1cc(c(Oc2ccc(cc2)N(c3ccc(N)cc3)c4ccc(N)cc4)c(c1)C(C)(C)C)C(C)(C)C'  # the extraordinary number of symmetries of this amine (\"4-N-(4-aminophenyl)-4-N-[4-(2,4,6-tritert-butylphenoxy)phenyl]benzene-1,4-diamine\")... \n",
    "]                                                                                 # ...mean it takes impractically long to isomorphism match during the Topology partition step\n",
    "\n",
    "banned_monomer_queries = {}\n",
    "for smiles in banned_monomers:\n",
    "    exp_spi = specification.expanded_SMILES(smiles, assign_map_nums=False)\n",
    "    banned_monomer_queries[smiles] = Chem.MolFromSmiles(exp_spi, sanitize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum, auto\n",
    "\n",
    "@dataclass\n",
    "class MonomerInfo:\n",
    "    '''For encapsulating salient info about an individual monomer'''\n",
    "    position      : int\n",
    "    smiles        : str\n",
    "    fn_group_name : str\n",
    "    IUPAC_name    : str\n",
    "\n",
    "class FilterRejectionReason(Enum):\n",
    "    '''For capturing information about which filtering step a monomer didn't pass'''\n",
    "    BAD_NUM_MONOMERS      = auto()\n",
    "    ILLEGAL_ATOMS         = auto()\n",
    "    NO_RXN_TEMPLATE_MATCH = auto()\n",
    "    BAD_NUM_FN_GRPS       = auto()\n",
    "    NO_IUPAC_NAME         = auto()\n",
    "    BANNED_MONOMER        = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cirpy\n",
    "import pubchempy as pcp\n",
    "\n",
    "def get_IUPAC_name(smiles : str, pc_prop_name : str='IUPACName') -> Optional[str]:\n",
    "    '''Takes the SMILES string representing a molecule and attempts to fetch its IUPAC name from NIH CACTUS and/or PubChem\n",
    "    Returns the fetched IUPAC name as a str, or NoneType if both queries fail'''\n",
    "    # Open with NIH query (fastest method), return name if found...\n",
    "    iupac_name = cirpy.resolve(smiles, 'iupac_name')\n",
    "    if iupac_name is not None:\n",
    "        return iupac_name \n",
    "    \n",
    "    # ...otherwise, search through PubChem Compound queries for a matching results\n",
    "    for prop_query in pcp.get_properties(pc_prop_name, smiles, namespace='smiles'):\n",
    "        if pc_prop_name in prop_query:\n",
    "            return prop_query[pc_prop_name]\n",
    "    else:\n",
    "        return None # TODO : add ChemSpider once I can obtain an API key (https://chemspipy.readthedocs.io/en/latest/guide/intro.html#apikey) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.monomers import specification\n",
    "from polymerist.maths.combinatorics.sequences import bin_ids_forming_sequence\n",
    "\n",
    "def process_monomer_input(smiles : str, mech_name : str) -> Union[FilterRejectionReason, list[MonomerInfo]]:\n",
    "    '''For screening and expanding SMILES input to the MD polymer building workflow'''\n",
    "    # 1) Determine number of distrinct monomers in passed SMILES string\n",
    "    indiv_smiles = smiles.split('.') # opting for direct string-based approach here rather than RDKit Mol fragmenting for speed, and to avoid clunky str -> Mol -> str conversion\n",
    "    num_monomers = len(indiv_smiles)\n",
    "    if num_monomers != 2:\n",
    "        return FilterRejectionReason.BAD_NUM_MONOMERS\n",
    "    \n",
    "    # Generate expanded SMILES string and corresponding RDKit Mol for all monomers\n",
    "    exp_smiles         : list[str     ] = []\n",
    "    indiv_monomers     : list[Chem.Mol] = []\n",
    "    mono_group_choices : list[Iterable[str]] = []\n",
    "    \n",
    "    for smi in indiv_smiles: # wait to expand SMILES until after count filtering for speed\n",
    "        exp_smi = specification.expanded_SMILES(smi, assign_map_nums=False)\n",
    "        monomer = Chem.MolFromSmiles(exp_smi, sanitize=False)\n",
    "\n",
    "        # 2) Catch monomers with illegal atoms or, if none are present, generate expanded SMILES string and corresponding RDKit Mol for all monomers\n",
    "        if any(queries.matching_labels_from_substruct_dict(monomer, illegal_chem_queries)): # if any illegal atoms are detected in the current monomer, return and exit\n",
    "            return FilterRejectionReason.ILLEGAL_ATOMS\n",
    "\n",
    "        exp_smiles.append(exp_smi)\n",
    "        indiv_monomers.append(monomer)\n",
    "        mono_group_choices.append(queries.matching_labels_from_substruct_dict(monomer, fn_group_queries)) # generate ordered list of functional group choice bins\n",
    "\n",
    "    # 3) Determine if monomer functionalizations match the advertised rxn, and if so in what order they should appear\n",
    "    reactive_groups : list[str] = rxn_groups[rxn_backmap[mech_name]]\n",
    "    all_indices     : set[int]  = set(range(num_monomers))\n",
    "    for mono_order in bin_ids_forming_sequence(sequence=reactive_groups, choice_bins=mono_group_choices):\n",
    "        if set(mono_order) == all_indices: # check to avoid duplication for multifunctional monomers\n",
    "            break # exit loop when first valid order is found\n",
    "    else:\n",
    "        return FilterRejectionReason.NO_RXN_TEMPLATE_MATCH\n",
    "    \n",
    "    # produce monomers based on a valid ordering if one is found\n",
    "    mono_info_list : list[MonomerInfo] = []\n",
    "    for i, mono_fn_group in zip(mono_order, reactive_groups, strict=True): # strict just gives one further safeguard that a 1:1 reactive group to monomer mapping has been found\n",
    "        monomer = indiv_monomers[i]\n",
    "        # 4) Exclude any monomers which are manually disallowed\n",
    "        if any(queries.matching_labels_from_substruct_dict(monomer, banned_monomer_queries)): # if any illegal atoms are detected in the current monomer, return and exit\n",
    "            return FilterRejectionReason.BANNED_MONOMER\n",
    "\n",
    "        # 5) Determine if all monomers are only have the desired functionalization numbers \n",
    "        if queries.num_substruct_queries_distinct(monomer, fn_group_queries[mono_fn_group]) != 2:\n",
    "            return FilterRejectionReason.BAD_NUM_FN_GRPS\n",
    "        \n",
    "        # 6) Query IUPAC names for each monomer - NOTE: not done in the monomer expansion loop as the name query is the slowest step and should preferably alled as few times as possible\n",
    "        iupac_name = get_IUPAC_name(exp_smiles[i])\n",
    "        if iupac_name is None:\n",
    "            return FilterRejectionReason.NO_IUPAC_NAME\n",
    "        \n",
    "        # if a monomer has gotten here, that means it's passed!\n",
    "        mono_info = MonomerInfo(\n",
    "            position=i,\n",
    "            smiles=exp_smiles[i],\n",
    "            fn_group_name=mono_fn_group,\n",
    "            IUPAC_name=iupac_name\n",
    "        )\n",
    "        mono_info_list.append(mono_info)\n",
    "\n",
    "    return mono_info_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate filtered Series (either error codes or MonomerInfo) from initial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import track\n",
    "\n",
    "targ_df = df\n",
    "# targ_df = df.head(30)\n",
    "# targ_df = df[df.mechanism == 'vinyl']\n",
    "\n",
    "proc_output = []\n",
    "for (i, row) in track(targ_df.iterrows(), total=len(targ_df), description='Processing SMILES dataset...'):\n",
    "    proc = process_monomer_input(row.smiles_monomer, row.mechanism)\n",
    "    proc_output.append(proc)\n",
    "\n",
    "proc_output = pd.Series(proc_output) # convert from list to Series, partition by failure state\n",
    "was_rejected = proc_output.map(lambda out : isinstance(out, FilterRejectionReason))\n",
    "rejects = proc_output[ was_rejected]\n",
    "passes  = proc_output[~was_rejected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expand successful monomers into labelled DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_mono_info_list(all_info : list[MonomerInfo]) -> list[str]:\n",
    "    return {\n",
    "        f'{attr}_monomer_{j}' : getattr(mono_info, attr)\n",
    "            for j, mono_info in enumerate(all_info) # NOTE: the index \"j\" here is NOT the position as determined by monomer sort, but rather the index in the rxn groups ordering\n",
    "                for attr in ('smiles', 'fn_group_name', 'IUPAC_name')\n",
    "    }\n",
    "\n",
    "passes_as_dict = passes.map(expand_mono_info_list)\n",
    "passes_df = pd.DataFrame.from_records(passes_as_dict.values, index=passes_as_dict.index)\n",
    "\n",
    "result_df = pd.concat([passes_df, df.loc[passes_df.index]], axis=1) # combine expanded monomer info with original dataframe\n",
    "result_df.insert( # insert row of backmapped rxn name to aoid lookup in subsequent pipeline steps\n",
    "    loc=result_df.columns.get_loc('mechanism'),\n",
    "    column='rxn_name',\n",
    "    value=result_df['mechanism'].map(rxn_backmap)\n",
    ")\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show distribution of failure cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 6\n",
    "aspect= 3/2\n",
    "\n",
    "plt.figure(figsize=(dim*aspect, dim))\n",
    "\n",
    "ax = rejects.map(lambda x : x.value).plot(kind='hist')\n",
    "ax.set_xticks([i.value for i in FilterRejectionReason])\n",
    "ax.set_xticklabels([i.name for i in FilterRejectionReason], rotation=-30)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save filtered DataFrame for next steps to avoid reprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROC_DATA_DIR.mkdir(exist_ok=True)\n",
    "clean_input_stem = input_data_path.stem.removesuffix('_FMT')\n",
    "\n",
    "# save filtered dataset to filtered directory to store caclulations\n",
    "out_data_path = PROC_DATA_DIR / f'{clean_input_stem}_FILTERED{input_data_path.suffix}'\n",
    "result_df.to_csv(out_data_path)\n",
    "\n",
    "# also keep record of the rejected monomers (and the reasons for rejection)\n",
    "rejects_data_path = PROC_DATA_DIR / f'{clean_input_stem}_REJECTED{input_data_path.suffix}'\n",
    "rejects.map(lambda r : r.name).to_csv(rejects_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
