{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Imports\n",
    "import re\n",
    "from functools import partial, cached_property\n",
    "from collections import defaultdict\n",
    "from itertools import combinations, chain\n",
    "from ast import literal_eval\n",
    "\n",
    "# Numeric imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# File I/O\n",
    "from pathlib import Path\n",
    "import csv, json, pickle\n",
    "\n",
    "# Logging\n",
    "from tqdm import tqdm as tqdm_text\n",
    "from tqdm.notebook import tqdm as tqdm_notebook\n",
    "\n",
    "# Typing and Subclassing\n",
    "from typing import Any, Callable, ClassVar, Generator, Iterable, Optional, Union\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdChemReactions\n",
    "\n",
    "from openff.toolkit import ForceField\n",
    "from openff.toolkit.topology import Topology, Molecule\n",
    "\n",
    "from openforcefields.openforcefields import get_forcefield_dirs_paths\n",
    "OPENFF_DIR = Path(get_forcefield_dirs_paths()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating OpenMM and LAMMPS systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Harvest and tabulate paths + info for all Interchange and Topology files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# MOL_MASTER_DIR = Path('polymer_structures')\n",
    "# MOL_MASTER_DIR = Path('polymer_validation')\n",
    "# MOL_MASTER_DIR = Path('polymer_revision')\n",
    "# MOL_MASTER_DIR = Path('polymer_update')\n",
    "# MOL_MASTER_DIR = Path('polymer_benchmark')\n",
    "MOL_MASTER_DIR = Path('polymer_benchmark_fastlmp')\n",
    "build_records_path = MOL_MASTER_DIR / 'build_records.csv'\n",
    "\n",
    "# mol_file_frame = pd.read_csv(build_records_path, index_col=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = (\n",
    "    'mechanism',\n",
    "    'polymer_name',\n",
    "    'oligomer_size',\n",
    "    'lattice_size'\n",
    ")\n",
    "\n",
    "records = []\n",
    "for mol_dir in MOL_MASTER_DIR.glob('**/[0-9]x[0-9]x[0-9]'):\n",
    "    mol_info = {\n",
    "        tag : value\n",
    "            for tag, value in zip(TAGS, mol_dir.relative_to(MOL_MASTER_DIR).parts)\n",
    "    }\n",
    "    mol_info['directory'] = mol_dir\n",
    "\n",
    "    record_path = mol_dir / f'{mol_info[\"lattice_size\"]}_{mol_info[\"oligomer_size\"]}_{mol_info[\"polymer_name\"]}_RECORD.json'\n",
    "    if record_path.exists:\n",
    "        with record_path.open('r') as record_file:\n",
    "            mol_info.update(json.load(record_file))\n",
    "\n",
    "    records.append(mol_info)\n",
    "\n",
    "mol_file_frame = pd.DataFrame.from_records(records)\n",
    "mol_file_frame.set_index(['mechanism', 'polymer_name'], inplace=True)\n",
    "groups = mol_file_frame.groupby(['lattice_size'])\n",
    "# groups = mol_file_frame.groupby(['lattice_size', 'mechanism'])\n",
    "\n",
    "# post-processing and typing\n",
    "mol_file_frame['records_path'] = None\n",
    "for str_path_col in ('topology_path', 'interchange_path', 'directory'):\n",
    "    mol_file_frame[str_path_col] = mol_file_frame[str_path_col].map(Path) # de-stringify file Paths\n",
    "groups = mol_file_frame.groupby(['lattice_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering by elements and compound name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benz_names = ('benzene', 'phenyl', 'benz', 'phen')\n",
    "desired_elems = ('F', 'N', 'O')\n",
    "\n",
    "has_elems = mol_file_frame['unique_elems_in_topology'].map(lambda x : all(elem in x for elem in desired_elems))\n",
    "has_benz = mol_file_frame.index.map(lambda x : any(bname in x[1] for bname in benz_names)).to_series(index=mol_file_frame.index)\n",
    "\n",
    "candidates = mol_file_frame[has_benz & has_elems]\n",
    "candidates[candidates['lattice_size'] == '1x1x1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from openmm import System, Context, NonbondedForce\n",
    "from openmm.unit import kilojoule_per_mole, Quantity\n",
    "from polymerist.genutils.containers import RecursiveDict\n",
    "\n",
    "\n",
    "## OpenMM\n",
    "NONBOND_CUTOFF_METHOD_NAMES = (\n",
    "    'NoCutoff',\n",
    "    'CutoffNonPeriodic',\n",
    "    'CutoffPeriodic',\n",
    "    'Ewald',\n",
    "    'PME',\n",
    "    'LJPME',\n",
    ")\n",
    "NONBOND_CUTOFF_METHODS = {\n",
    "    idx : method_name\n",
    "        for idx, method_name in sorted( # sort in ascending order by integer code\n",
    "            (getattr(NonbondedForce, method_name), method_name)\n",
    "                for method_name in NONBOND_CUTOFF_METHOD_NAMES\n",
    "        )\n",
    "}\n",
    "\n",
    "def describe_ommsys_forces(ommsys : System) -> tuple[dict[str, dict[str, str]], dict[str, int]]:\n",
    "    '''Describes accessible parameters associated with each Force in an OpenMM system\n",
    "    Also maps each Force's force_group to a unique id\n",
    "\n",
    "    Returns the decriptive text as a string, and a dict mapping each Force's name to it's id'''\n",
    "    force_map : dict[str, int] = {}\n",
    "    descript_dict = RecursiveDict()\n",
    "\n",
    "    for force in ommsys.getForces():\n",
    "        force_name = force.getName()\n",
    "        force_map[force_name] = force.getForceGroup()\n",
    "        descript_dict[force_name]['type'] = type(force).__name__\n",
    "        \n",
    "        for attr in dir(force):\n",
    "            if attr.startswith('get'):\n",
    "                try:\n",
    "                    attr_val = getattr(force, attr)()\n",
    "                    if attr == 'getNonbondedMethod': # convert integer index into readable name of nonbonded cutoff method\n",
    "                        attr_val = NONBOND_CUTOFF_METHODS[attr_val]\n",
    "                    descript_dict[force_name][attr.removeprefix('get')] = attr_val\n",
    "                except TypeError: # called when the getter expects more than 0 arguments\n",
    "                    pass\n",
    "                \n",
    "    return descript_dict, force_map\n",
    "\n",
    "def eval_openmm_energies(context : Context, force_name_remap : Optional[dict[str, str]]=None) -> dict[str, Quantity]:\n",
    "    '''Perform an energy evaluation on an OpenMM Context'''\n",
    "    if force_name_remap is None:\n",
    "        force_name_remap = {}\n",
    "    openmm_energies = {}\n",
    "\n",
    "    # get global energies\n",
    "    overall_state = context.getState(getEnergy=True) # get total potential energy\n",
    "    openmm_energies['Potential'] = overall_state.getPotentialEnergy()\n",
    "    openmm_energies['Kinetic'  ] = overall_state.getKineticEnergy()\n",
    "\n",
    "    # get individual energies from each force type\n",
    "    for i, force in enumerate(context.getSystem().getForces()):\n",
    "        state = context.getState(getEnergy=True, groups={i}) # TODO : add option to keep whatever groups were there prior\n",
    "        force_label = force_name_remap.get(force.getName(), force.getName()) # check if a remapped name is registered, otherwise use the Force's set name\n",
    "        openmm_energies[force_label] = state.getPotentialEnergy()\n",
    "\n",
    "    return openmm_energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create MD files from Interchange, evaluate starting energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openmm import Integrator, Context\n",
    "\n",
    "from openff.interchange import Interchange\n",
    "from openff.interchange.constants import _PME\n",
    "from openff.interchange.components.mdconfig import MDConfig\n",
    "from openff.interchange.interop.openmm._positions import to_openmm_positions\n",
    "\n",
    "from polymerist.openmmtools import serialization, preparation\n",
    "\n",
    "\n",
    "STATE_PARAMS : dict[str, bool] = {\n",
    "    'getPositions'  : True,\n",
    "    'getVelocities' : True,\n",
    "    'getForces'     : True,\n",
    "    'getEnergy'     : True,\n",
    "    'getParameters' : True,\n",
    "    'getParameterDerivatives' : False,\n",
    "    'getIntegratorParameters' : True\n",
    "}\n",
    "\n",
    "def interchange_to_lammps(interchange : Interchange, lmp_data_path : Path, lmp_input_path : Path) -> None:\n",
    "    '''Produce LAMMPS input and data files from an OpenFF Interchange'''\n",
    "    interchange.to_lammps(lmp_data_path) # MD data file\n",
    "    mdc = MDConfig.from_interchange(interchange)\n",
    "    # mdc.write_lammps_input(lmp_input_path) # input directive file\n",
    "    mdc.write_lammps_input(lmp_input_path, interchange) # input directive file\n",
    "\n",
    "    # replacing generic lmp file with data file from above\n",
    "    with lmp_input_path.open('r') as in_file:\n",
    "        in_file_block = in_file.read()\n",
    "\n",
    "    with lmp_input_path.open('w') as in_file:\n",
    "        in_file.write(\n",
    "            in_file_block.replace('out.lmp', f'\"{lmp_data_path}\"') # need surrounding double quotes to allow LAMMPS to read special symbols in filename (if present)\n",
    "        )\n",
    "\n",
    "def interchange_to_openmm(interchange : Interchange, integrator : Integrator, omm_sys_path : Path, omm_state_path : Path) -> Context:\n",
    "    '''Produce OpenMM System and State .xml files from an OpenFF Interchange'''\n",
    "    system = interchange.to_openmm(combine_nonbonded_forces=False)\n",
    "    preparation.label_forces(system)\n",
    "    context = Context(system, integrator)\n",
    "    context.setPositions(to_openmm_positions(interchange, include_virtual_sites=True))\n",
    "\n",
    "    ## writing OpenMM files\n",
    "    serialization.serialize_system(omm_sys_path, system)\n",
    "    serialization.serialize_state_from_context(omm_state_path, context, state_params=STATE_PARAMS)\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cProfile\n",
    "\n",
    "from gc import collect\n",
    "from shutil import copyfile\n",
    "from IPython.display import clear_output\n",
    "from rich.progress import Progress\n",
    "\n",
    "from polymerist.genutils.fileutils.pathutils import assemble_path\n",
    "from polymerist.genutils.fileutils.jsonio.update import append_to_json\n",
    "\n",
    "from polymerist.duration import Timer\n",
    "from polymerist.lammpstools import lammpseval\n",
    "from polymerist.openfftools import topology\n",
    "\n",
    "from polymerist.openmmtools.thermo import EnsembleFactory\n",
    "from polymerist.openmmtools.parameters import SimulationParameters\n",
    "\n",
    "\n",
    "# parameters\n",
    "sim_params = SimulationParameters.from_file('sim_params.json')\n",
    "ensfac = EnsembleFactory.from_thermo_params(sim_params.thermo_params)\n",
    "\n",
    "build_lammps : bool = True\n",
    "build_openmm : bool = False#True\n",
    "\n",
    "force_name_remap = { # easier-to-understand names for OpenMM energies\n",
    "    'vdW force'                : 'vdW',\n",
    "    'Electrostatics force'     : 'Electrostatic',\n",
    "    'vdW 1-4 force'            : 'vdW 1-4',\n",
    "    'Electrostatics 1-4 force' : 'Electrostatic 1-4',\n",
    "    'PeriodicTorsionForce'     : 'Dihedral',\n",
    "    'HarmonicAngleForce'       : 'Angle',\n",
    "    'HarmonicBondForce'        : 'Bond'\n",
    "}\n",
    "\n",
    "# execute MD loop\n",
    "for lattice_size in groups.groups.keys():\n",
    "    print(lattice_size)\n",
    "    targ_df = groups.get_group(lattice_size)\n",
    "    energies = RecursiveDict()\n",
    "    with Progress() as progress:\n",
    "        mol_task_id = progress.add_task('Generating MD files', total=len(targ_df))\n",
    "\n",
    "        for (mechanism, mol_name), row in targ_df.iterrows():\n",
    "            # load recorded topology and interchange files\n",
    "            progress.update(mol_task_id, description=f'{mechanism} : {mol_name}')\n",
    "\n",
    "            mol_record_path = row.directory / f'{row.lattice_size}_{row.oligomer_type}_{mol_name}_RECORD.json'\n",
    "            targ_df.loc[(mechanism, mol_name), 'records_path'] = mol_record_path if mol_record_path.exists() else None\n",
    "\n",
    "            offtop = topology.topology_from_sdf(row.topology_path, allow_undefined_stereo=True)\n",
    "            with row.interchange_path.open('rb') as inc_file:\n",
    "                interchange = pickle.load(inc_file)\n",
    "\n",
    "            # LAMMPS\n",
    "            if build_lammps:\n",
    "                lmp_dir : Path = row.directory / 'LAMMPS'\n",
    "                lmp_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                lmp_data_path  = assemble_path(lmp_dir, mol_name, extension='lammps')\n",
    "                lmp_input_path = assemble_path(lmp_dir, mol_name, extension='in')\n",
    "                lmp_prof_path  = assemble_path(lmp_dir, mol_name, extension='txt', postfix='profile')\n",
    "\n",
    "                ## writing LAMMPS files\n",
    "                with Timer() as lammps_timer:\n",
    "                    lmp_profile = cProfile.Profile()\n",
    "                    lmp_ret = lmp_profile.runcall(\n",
    "                        interchange_to_lammps,\n",
    "                        interchange=interchange,\n",
    "                        lmp_data_path=lmp_data_path,\n",
    "                        lmp_input_path=lmp_input_path\n",
    "                    )\n",
    "                    \n",
    "                lmp_profile.dump_stats(lmp_prof_path)\n",
    "                if mol_record_path.exists():\n",
    "                    append_to_json(mol_record_path, lammps_time=lammps_timer.time_taken)\n",
    "\n",
    "                ## evaluating LAMMPS energies\n",
    "                # box_params = lammpseval.get_lammps_unit_cell(lmp_input_path)\n",
    "                energies['LAMMPS'][(mechanism, mol_name)] = lammpseval.get_lammps_energies(lmp_input_path, preferred_unit=kilojoule_per_mole)\n",
    "                # clear_output()\n",
    "\n",
    "            # OpenMM\n",
    "            if build_openmm:\n",
    "                omm_dir : Path = row.directory / 'OpenMM'\n",
    "                omm_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                omm_sys_path   = assemble_path(omm_dir, mol_name, postfix='system'  , extension='xml')\n",
    "                omm_state_path = assemble_path(omm_dir, mol_name, postfix='state'   , extension='xml')\n",
    "                omm_top_path   = assemble_path(omm_dir, mol_name, postfix='topology', extension='sdf') \n",
    "                omm_prof_path  = assemble_path(omm_dir, mol_name, postfix='profile', extension='txt')\n",
    "\n",
    "                integrator = ensfac.integrator(time_step=sim_params.integ_params.time_step)\n",
    "\n",
    "                with Timer() as openmm_timer:\n",
    "                    omm_profile = cProfile.Profile()\n",
    "                    context = omm_profile.runcall(\n",
    "                        interchange_to_openmm,\n",
    "                        interchange=interchange,\n",
    "                        integrator=integrator,\n",
    "                        omm_sys_path=omm_sys_path,\n",
    "                        omm_state_path=omm_state_path\n",
    "                    )\n",
    "                    copyfile(row.topology_path, omm_top_path) # TODO : PDB?\n",
    "\n",
    "                omm_profile.dump_stats(omm_prof_path)\n",
    "                if mol_record_path.exists():\n",
    "                    append_to_json(mol_record_path, openmm_time=openmm_timer.time_taken)\n",
    "                    \n",
    "                ## evaluating OpenMM energies\n",
    "                openmm_energies = eval_openmm_energies(context, force_name_remap=force_name_remap)\n",
    "                assert(openmm_energies['Kinetic'] == 0.0*kilojoule_per_mole) # check total KE to verify no integration is being done\n",
    "                energies['OpenMM'][(mechanism, mol_name)] = openmm_energies\n",
    "\n",
    "            progress.advance(mol_task_id)\n",
    "            collect() # manual garbage collector call to try to alleviate memory issues\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_dir = Path('energy_tables')\n",
    "energy_dir.mkdir(exist_ok=True)\n",
    "edfs = {}\n",
    "\n",
    "for (label, energies_dict) in energies.items():\n",
    "    energy_path = assemble_path(energy_dir, label, postfix=f'{MOL_MASTER_DIR.stem}_{lattice_size}', extension='csv')\n",
    "    edf = pd.DataFrame.from_dict(energies_dict, orient='index')\n",
    "    edf.to_csv(energy_path)\n",
    "    edfs[label] = edf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading energy tables and comparing contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from operator import add\n",
    "\n",
    "pd.options.display.float_format = '{:.4f}'.format # disable scientific notation\n",
    "\n",
    "@dataclass\n",
    "class TableFormats:\n",
    "    sum_terms : dict[str, list[str]]\n",
    "    del_terms : list[str]\n",
    "\n",
    "formats = {\n",
    "    'OpenMM' : TableFormats(\n",
    "        sum_terms = {\n",
    "            'vdW' : ['vdW', 'vdW 1-4'],\n",
    "            'Coulomb' : ['Electrostatic', 'Electrostatic 1-4']\n",
    "        },\n",
    "        del_terms = ['Kinetic']\n",
    "    ),\n",
    "    'LAMMPS' : TableFormats(\n",
    "        sum_terms = {\n",
    "            'vdW' : ['vdW', 'Dispersion'],\n",
    "            'Dihedral' : ['Proper Torsion', 'Improper Torsion'],\n",
    "            'Coulomb'  : ['Coulomb Short', 'Coulomb Long']\n",
    "        },\n",
    "        del_terms = ['Nonbonded']\n",
    "    ),\n",
    "}\n",
    "\n",
    "# apply reformatting to respective tables\n",
    "edfs_fmt = {}\n",
    "for platform, energy_df in edfs.items():\n",
    "    fmt = formats[platform]\n",
    "\n",
    "    # combine selected terms\n",
    "    new_energy_df = energy_df.copy(deep=True) # leave original unmodified\n",
    "    for combined_contrib, contribs in fmt.sum_terms.items():\n",
    "        new_term = reduce(add, (new_energy_df[contrib] for contrib in contribs)) # merge contributions into a single new named term\n",
    "        new_energy_df = new_energy_df.drop(columns=contribs, inplace=False) # clear contributions\n",
    "        new_energy_df[combined_contrib] = new_term # done after drop to ensure name clashes don't result in extra deletion\n",
    "    \n",
    "    # delete redundant terms\n",
    "    for del_contrib in fmt.del_terms:\n",
    "        new_energy_df.drop(columns=[del_contrib], inplace=True) # clear contributions\n",
    "    edfs_fmt[platform] = new_energy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from polymerist.graphics.plotutils import presize_subplots\n",
    "\n",
    "\n",
    "col_order = ['Bond', 'Angle', 'Dihedral', 'vdW', 'Coulomb', 'Potential']\n",
    "max_err_perc : float = None\n",
    "# max_err_perc : float = 100.0\n",
    "\n",
    "energy_perc_rel_err = ((edfs_fmt['OpenMM'] - edfs_fmt['LAMMPS']) / edfs_fmt['LAMMPS']).abs() * 100\n",
    "if max_err_perc:\n",
    "    err_in_tol = (energy_perc_rel_err.abs() < max_err_perc).all(axis=1)\n",
    "    energy_perc_rel_err = energy_perc_rel_err[err_in_tol]\n",
    "\n",
    "fig, ax = presize_subplots(nrows=2, ncols=3)\n",
    "for col, axis in zip(col_order, ax.flatten()):\n",
    "    heights, bins, patches = axis.hist(energy_perc_rel_err[col], bins=50)\n",
    "    axis.set_ylabel(f'{col} energy (rel. % error)')\n",
    "    axis.tick_params(axis='x', rotation=-20)\n",
    "    \n",
    "plt.show()\n",
    "display(energy_perc_rel_err[col_order])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_path = assemble_path(energy_dir, 'Energy_rel_err_table', postfix=f'{MOL_MASTER_DIR.stem}_{lattice_size}', extension='csv')\n",
    "energy_perc_rel_err.to_csv(diff_path)\n",
    "\n",
    "energy_fig_path = assemble_path(energy_dir, 'Energy_rel_err_graphs', postfix=f'{MOL_MASTER_DIR.stem}_{lattice_size}', extension='png')\n",
    "fig.savefig(energy_fig_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting just the systems which have density data available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polymer_name(row : pd.Series) -> str:\n",
    "    return f'poly({row[\"IUPAC_name_monomer_0\"]}-co-{row[\"IUPAC_name_monomer_1\"]})'.lower()\n",
    "\n",
    "p = Path('monomer_data_processed/monomer_data_MASTER.csv')\n",
    "polyid_df = pd.read_csv(p, index_col=0)\n",
    "\n",
    "polyid_df['polymer_name'] = polyid_df.apply(get_polymer_name, axis=1) # generate column of polymer names from monomer names\n",
    "polyid_df.set_index(['rxn_name', 'polymer_name'], inplace=True) # reindex by mechanism and molecule name\n",
    "polyid_df = polyid_df[polyid_df['Density'].notnull()] # filter by density values\n",
    "\n",
    "common_index = polyid_df.index.intersection(energy_perc_rel_err.index)\n",
    "polyid_df.loc[common_index]['Density']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_density = energy_perc_rel_err.loc[common_index]\n",
    "has_density['Density'] = polyid_df.loc[common_index]['Density']\n",
    "has_density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from polymerist.graphics import plotutils\n",
    "\n",
    "plot_pairs = (\n",
    "    ('n_atoms_in_topology', 'topology_time'), # TOSELF : can't \n",
    "    ('n_atoms_in_topology', 'interchange_time'),\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plotutils.presize_subplots(nrows=1, ncols=len(plot_pairs))\n",
    "for axis, (x_var, y_var) in zip(ax, plot_pairs):\n",
    "    axis.scatter(mol_file_frame[x_var], mol_file_frame[y_var])\n",
    "    axis.set_xlabel(x_var)\n",
    "    axis.set_ylabel(y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
