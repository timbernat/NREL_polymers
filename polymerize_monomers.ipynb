{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510f62af915d48ef9c5f59581c88bec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Logging and Shell\n",
    "import logging\n",
    "\n",
    "from polymerist.openfftools.partialcharge import molchargers\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    force=True\n",
    ")\n",
    "\n",
    "## Generic imports\n",
    "from typing import Any, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "## Numeric imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## File I/O\n",
    "from pathlib import Path\n",
    "import json, pickle\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "\n",
    "from openmm.unit import nanometer, angstrom, Quantity\n",
    "\n",
    "from openff.toolkit import Molecule, Topology, ForceField\n",
    "from openff.toolkit.utils.exceptions import (\n",
    "    UnassignedChemistryInPDBError,\n",
    "    IncorrectNumConformersWarning,\n",
    ")\n",
    "\n",
    "# Custom Imports\n",
    "from polymerist.genutils.containers import RecursiveDict\n",
    "from polymerist.genutils.fileutils import filetree\n",
    "from polymerist.genutils.fileutils.pathutils import assemble_path\n",
    "from polymerist.duration import Duration, Timer\n",
    "from polymerist.unitutils.interop import openmm_to_openff, openff_to_openmm\n",
    "\n",
    "from polymerist.maths.greek import GREEK_PREFIXES\n",
    "from polymerist.rdutils.rdprops import copy_rd_props\n",
    "from polymerist.rdutils.rdcoords.tiling import rdmol_effective_radius\n",
    "from polymerist.rdutils.reactions import reactions, reactors\n",
    "\n",
    "from polymerist.openfftools.partition import partition\n",
    "from polymerist.openfftools import topology, boxvectors, FFDIR\n",
    "from polymerist.monomers import specification, MonomerGroup\n",
    "from polymerist.polymers import building\n",
    "\n",
    "# catch annoying warnings\n",
    "import warnings \n",
    "warnings.catch_warnings(record=True)\n",
    "warnings.filterwarnings('ignore', category=IncorrectNumConformersWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load monomer and rxn data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Paths\n",
    "RAW_DATA_DIR  = Path('monomer_data_raw')\n",
    "FMT_DATA_DIR  = Path('monomer_data_formatted')\n",
    "PROC_DATA_DIR = Path('monomer_data_processed')\n",
    "RXN_FILES_DIR = Path('poly_rxns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data_path = PROC_DATA_DIR / '20231114_polyid_data_density_DP2-6 - 1,2 monomers_FILTERED.csv'\n",
    "# input_data_path = PROC_DATA_DIR / 'nipu_urethanes_FILTERED.csv'\n",
    "input_data_path = PROC_DATA_DIR / 'monomer_data_MASTER.csv'\n",
    "df = pd.read_csv(input_data_path, index_col=[0,1])\n",
    "df = df.replace(np.nan, None) # swap NaN values for explicit NoneTypes to simplify value write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchsamp = pd.read_csv('oligomers_for_benchmark.csv', index_col=[0,1])\n",
    "# df = df.loc[benchsamp.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-defined reactions with functional group and name backmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_first_n : Optional[int] = None # debug option to only take a handful of compounds from each family\n",
    "# take_first_n : Optional[int] = 1\n",
    "blacklisted_rxns = ['polyimide']#, 'polyvinyl_head_tail']\n",
    "\n",
    "frames_by_mech : dict[str, pd.DataFrame] = {}\n",
    "for rxn_name in df.index.unique(level='mechanism'):\n",
    "    if rxn_name in blacklisted_rxns:\n",
    "        continue\n",
    "\n",
    "    rxn_df = df.xs(rxn_name)\n",
    "    if take_first_n is not None:\n",
    "        rxn_df = rxn_df.head(take_first_n)\n",
    "    frames_by_mech[rxn_name] = rxn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (RXN_FILES_DIR / 'rxn_groups.json').open('r') as file: # load table of functional group for each reaction\n",
    "    rxn_groups = json.load(file)\n",
    "\n",
    "rxns = {\n",
    "    rxnname : reactions.AnnotatedReaction.from_rxnfile(RXN_FILES_DIR / f'{rxnname}.rxn')\n",
    "        for rxnname in rxn_groups.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-generating monomer fragments and Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and format progress bars to track build status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import Progress\n",
    "from rich.progress import (\n",
    "    BarColumn,\n",
    "    Progress,\n",
    "    SpinnerColumn,\n",
    "    TaskProgressColumn,\n",
    "    TextColumn,\n",
    "    TimeElapsedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "from rich.console import Group\n",
    "from rich.live import Live\n",
    "\n",
    "# status of individual task\n",
    "status_readout = Progress(\n",
    "    'STATUS:',\n",
    "    TextColumn(\n",
    "        '[purple]{task.fields[action]}'\n",
    "    ),\n",
    "    '...'\n",
    ")\n",
    "status_id = status_readout.add_task('[green]Current compound:', action='')\n",
    "\n",
    "# textual display of the name of the curent polymer\n",
    "compound_readout = Progress(\n",
    "    'Current compound:',\n",
    "    TextColumn(\n",
    "        '[blue]{task.fields[polymer_name]}',\n",
    "        justify='right'\n",
    "    )\n",
    ")\n",
    "curr_compound_id  = compound_readout.add_task('[green]Compound:', polymer_name='')\n",
    "\n",
    "# progress over individual compounds (irrespective of mechanism)\n",
    "compound_progress = Progress(\n",
    "    SpinnerColumn(),\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    ")\n",
    "comp_progress_id = compound_progress.add_task('[blue]Unique compound(s)   ', polymer_name='')\n",
    "\n",
    "# progress over distinct classes of mechanism\n",
    "inter_mech_progress = Progress(\n",
    "    SpinnerColumn(),\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    ")\n",
    "curr_mechanism_id = inter_mech_progress.add_task('[blue]Reaction mechanism(s)', start=True, total=len(frames_by_mech))\n",
    "\n",
    "# individual progress bars for compounds within each mechanism\n",
    "intra_mech_progress = Progress(\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    "    'At:',\n",
    "    TimeElapsedColumn(),\n",
    ")\n",
    "total_compounds = 0\n",
    "mech_task_ids = {} # preprocess dataframes by mechanism to determine progress bar layout and task lengths\n",
    "for rxn_name, rxn_df in frames_by_mech.items():\n",
    "    num_compounds = len(rxn_df)\n",
    "    mech_task_ids[rxn_name] = intra_mech_progress.add_task(f'[cyan]{rxn_name}', start=True, total=len(rxn_df))\n",
    "    total_compounds += num_compounds\n",
    "compound_progress.update(curr_compound_id, total=total_compounds)\n",
    "\n",
    "# combine progess readouts into unified live console\n",
    "group = Group(\n",
    "    status_readout,\n",
    "    compound_readout,\n",
    "    compound_progress,\n",
    "    inter_mech_progress,\n",
    "    intra_mech_progress,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from time import sleep, time\n",
    "from polymerist.rdutils.rdtypes import RDMol\n",
    "from polymerist.maths.lattices.integral import CubicIntegerLattice\n",
    "\n",
    "\n",
    "HILL_REGEX = re.compile(r'([A-Z][a-z]?)[0-9]*?') # break apart hill formula into just unique elements (one capital letter, one or no lowercase letters, any (including none) digits)\n",
    "\n",
    "def generate_smarts_fragments(reactants_dict : dict[str, RDMol], reactor : reactors.PolymerizationReactor) -> MonomerGroup:\n",
    "    '''Takes a labelled dict of reactant Mols and a PolymerizationReactor object with predefined rxn mechanism\n",
    "    Returns a MonomerGroup containing all fragments enumerated by the provided rxn'''\n",
    "    monogrp = MonomerGroup()\n",
    "    initial_reactants = [reactants for reactants in reactants_dict.values()] # must convert to list to pass to ChemicalReaction\n",
    "    \n",
    "    for intermediates, frags in reactor.propagate(initial_reactants):\n",
    "        for assoc_group_name, rdfragment in zip(reactants_dict.keys(), frags):\n",
    "            # generate spec-compliant SMARTS\n",
    "            raw_smiles = Chem.MolToSmiles(rdfragment)\n",
    "            exp_smiles = specification.expanded_SMILES(raw_smiles)\n",
    "            spec_smarts = specification.compliant_mol_SMARTS(exp_smiles)\n",
    "\n",
    "            # record to monomer group\n",
    "            affix = 'TERM' if MonomerGroup.is_terminal(rdfragment) else 'MID'\n",
    "            monogrp.monomers[f'{assoc_group_name}_{affix}'] = [spec_smarts]\n",
    "\n",
    "    return monogrp\n",
    "\n",
    "def generate_uniform_subpopulated_lattice(max_num_atoms : int, num_atoms_in_mol : int, dimension : int=3) -> CubicIntegerLattice:\n",
    "    '''Create an integer lattice which accomodates a number of sites while minimizing the size of consecutive voids between empty sites'''\n",
    "    num_mols = max_num_atoms // num_atoms_in_mol # NOTE: key that this is floor division and not ordinary division\n",
    "    sidelen = np.ceil(num_mols**(1/dimension)).astype(int) # needed to bypass float-typing for integer-valued quantity\n",
    "    sidelens = np.array([sidelen]*dimension)\n",
    "    full_lattice = CubicIntegerLattice(sidelens)\n",
    "\n",
    "    # determine how many odd and even sublattice sites to sample\n",
    "    num_even_sites = full_lattice.even_idxs.size\n",
    "    num_even_to_take = min(num_mols, num_even_sites)     # lower bound on occupancy in d-dims is 0.5**(d-1) (=0.25 when d=3), meaning half lattice is not guaranteed to be occupied\n",
    "    num_odd_to_take  = max(0, num_mols - num_even_sites) # only choose odd sites if there are any remaining once filling the even sites\n",
    "\n",
    "    # randomly subsample appropriate amounts of each sublattice\n",
    "    even_idxs_to_keep = np.random.permutation(full_lattice.even_idxs)[:num_even_to_take] # if the even lattice is unfilled, this improves spread, and if it is full this doesn't matter\n",
    "    odd_idxs_to_keep  = np.random.permutation(full_lattice.odd_idxs )[:num_odd_to_take ] # populate interstices randmoly to avoid bias towards any part of the box\n",
    "    idxs_to_keep = np.concatenate([even_idxs_to_keep, odd_idxs_to_keep])\n",
    "    full_lattice.points = full_lattice.points[idxs_to_keep]\n",
    "\n",
    "    return full_lattice # TOSELF: naming here no longer makes sense as lattice is not technically full anymore: worth fixing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters for build process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASTER_OUT_DIR = Path('polymer_improved')\n",
    "MASTER_OUT_DIR = Path('polymers_atom_limited')\n",
    "\n",
    "DOPs : list[int] = [3]\n",
    "charge_method : str = 'Espaloma-AM1-BCC'\n",
    "force_field_name : str = 'openff_unconstrained-2.0.0.offxml' # 'openff-2.0.0.offxml'\n",
    "max_num_atoms_array : tuple[int] = (10_000, 20_000,)\n",
    "\n",
    "switching_function : bool = False\n",
    "exclusion : Quantity = 0.0 * nanometer \n",
    "nonbond_cutoff : Quantity = 0.9 * nanometer\n",
    "\n",
    "clear_existing           : bool = True#False\n",
    "refragment               : bool = False  \n",
    "repolymerize_pdbs        : bool = False\n",
    "reparameterize           : bool = False\n",
    "reassign_partial_charges : bool = False\n",
    "perform_energy_min       : bool = True\n",
    "\n",
    "# preprocess parameters\n",
    "charger = molchargers.MolCharger.subclass_registry[charge_method]()\n",
    "forcefield = ForceField(FFDIR / force_field_name)\n",
    "\n",
    "min_box_dim : Quantity = 2 * nonbond_cutoff # should be at least twice the nonbonded cutoff to avoid self-interaction\n",
    "min_bbox = openmm_to_openff(min_box_dim * np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute build loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b481102858d4f9ca4f1e9a2038033d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/mbuild/compound.py:2888: UserWarning: \n",
       "Performing energy minimization using the Open Babel package. Please refer to the documentation to find the \n",
       "appropriate citations for Open Babel and the UFF force field\n",
       "  warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/mbuild/compound.py:2888: UserWarning: \n",
       "Performing energy minimization using the Open Babel package. Please refer to the documentation to find the \n",
       "appropriate citations for Open Babel and the UFF force field\n",
       "  warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/mbuild/conversion.py:1849: UserWarning: \n",
       "The bond orders will be guessed using pybelOBMol.PerceviedBondOrders()\n",
       "  warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/mbuild/conversion.py:1849: UserWarning: \n",
       "The bond orders will be guessed using pybelOBMol.PerceviedBondOrders()\n",
       "  warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/dgl/heterograph.py:92: DGLWarning: \n",
       "Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
       "  dgl_warning(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/dgl/heterograph.py:92: DGLWarning: \n",
       "Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
       "  dgl_warning(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create directories\n",
    "MASTER_OUT_DIR.mkdir(exist_ok=True)\n",
    "if clear_existing:\n",
    "    filetree.clear_dir(MASTER_OUT_DIR)\n",
    "\n",
    "# set up data structures for global output\n",
    "failure_record = RecursiveDict()\n",
    "m2p_mismatches = RecursiveDict()\n",
    "\n",
    "# execute build loop\n",
    "num_successful : int = 0\n",
    "md_build_records : list[dict[str, Any]] = []\n",
    "with Live(group, refresh_per_second=10) as live:\n",
    "    # ensure bars start at 0\n",
    "    for pbar in group.renderables: \n",
    "        for task_id in pbar.task_ids:\n",
    "            pbar.reset(task_id)\n",
    "\n",
    "    # iterate over all distinct chemistries by reaction mechanism\n",
    "    for rxn_name, rxn_df in frames_by_mech.items():\n",
    "        # look up reactive groups and pathway by mechanism\n",
    "        mech_task_id = mech_task_ids[rxn_name]\n",
    "        rxn_pathway  = rxns[rxn_name]\n",
    "        reactor = reactors.PolymerizationReactor(rxn_pathway)\n",
    "        \n",
    "        # initialize output directories\n",
    "        mech_dir : Path = MASTER_OUT_DIR / rxn_name\n",
    "        mech_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        for (polymer_name, row) in rxn_df.iterrows():\n",
    "            compound_readout.update(curr_compound_id, polymer_name=polymer_name)\n",
    "            chem_dir : Path = mech_dir / polymer_name\n",
    "            chem_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            # 0) load reactants with IUPAC names from chemical table\n",
    "            status_readout.update(status_id, action='Gathering reactants')\n",
    "            named_reactants = {}\n",
    "            for j in range(2):\n",
    "                reactant = Chem.MolFromSmiles(row[f'smiles_monomer_{j}'], sanitize=False)\n",
    "                Chem.SanitizeMol(reactant, sanitizeOps=specification.SANITIZE_AS_KEKULE)\n",
    "                named_reactants[ row[f'IUPAC_name_monomer_{j}'] ] = reactant\n",
    "\n",
    "            try:\n",
    "                # 1) use rxn template to polymerize monomers into all possible fragments\n",
    "                frag_path = assemble_path(chem_dir, polymer_name, extension='json')\n",
    "                if frag_path.exists() and not refragment: # if fragments have already been \n",
    "                    status_readout.update(status_id, action='Loading pre-existing monomer fragments')\n",
    "                    monogrp = MonomerGroup.from_file(frag_path)\n",
    "                else:\n",
    "                    status_readout.update(status_id, action='Generating monomer fragments via reaction mechanism')\n",
    "                    monogrp = generate_smarts_fragments(named_reactants, reactor=reactor)\n",
    "\n",
    "                    status_readout.update(status_id, action='Saving monomer fragments...')\n",
    "                    monogrp.to_file(frag_path)\n",
    "\n",
    "                for dop in DOPs:\n",
    "                    nmer_name = f'{GREEK_PREFIXES[dop]}mer'\n",
    "                    dop_dir : Path = chem_dir / nmer_name\n",
    "                    dop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                    # 2) Generate PDB file for linear chain from fragments\n",
    "                    pdb_path : Path = assemble_path(dop_dir, polymer_name, extension='pdb')\n",
    "                    if not pdb_path.exists() or repolymerize_pdbs:\n",
    "                        status_readout.update(status_id, action=f'Generating PDB file (with{\"\" if perform_energy_min else \"out\"} UFF energy minimization)')\n",
    "                        polymer = building.build_linear_polymer(monomers=monogrp, DOP=dop+1, sequence='BA', energy_minimize=perform_energy_min)  # \"BA\" is needed to make term groups align properly, DOP does not account for term group pair (hence the \"+1\")\n",
    "                        building.mbmol_to_openmm_pdb(pdb_path, polymer)\n",
    "                        \n",
    "                        # checking that my method produces the same results as M2P\n",
    "                        m2p_smiles = row.smiles_polymer_DP6\n",
    "                        if m2p_smiles is not None:\n",
    "                            m2p_mol = Chem.MolFromSmiles(m2p_smiles)\n",
    "                            workflow_smiles = polymer.to_smiles()\n",
    "                            workflow_mol    = Chem.MolFromSmiles(workflow_smiles)\n",
    "\n",
    "                            if not (workflow_mol.HasSubstructMatch(m2p_mol) or m2p_mol.HasSubstructMatch(workflow_mol)):\n",
    "                                m2p_mismatches[rxn_name][polymer_name]['M2P_vers'] = m2p_smiles\n",
    "                                m2p_mismatches[rxn_name][polymer_name]['workflow_vers'] = workflow_smiles\n",
    "\n",
    "                    # 3a) Assign chemical info to PDB system\n",
    "                    param_top_path : Path = assemble_path(dop_dir, polymer_name, extension='sdf')\n",
    "                    if param_top_path.exists() and not reparameterize:\n",
    "                        status_readout.update(status_id, action='Loading parameterized single-mol Topology')\n",
    "                        offtop = topology.topology_from_sdf(param_top_path)\n",
    "                    else:\n",
    "                        try:\n",
    "                            status_readout.update(status_id, action='Partitioning topology by fragments')\n",
    "                            offtop = Topology.from_pdb(pdb_path, _custom_substructures=monogrp.monomers)\n",
    "                            assert(partition(offtop)) # verify that a partition was possible\n",
    "                            topology.topology_to_sdf(param_top_path, offtop)\n",
    "                        except UnassignedChemistryInPDBError:\n",
    "                            failure_record['No substruct cover'][rxn_name][polymer_name][dop] = monogrp\n",
    "                            continue # skip to next compounds, don't proceed with parameterization   \n",
    "                        except AssertionError:\n",
    "                            failure_record['No substruct partition'][rxn_name][polymer_name][dop] = monogrp\n",
    "                            continue # skip to next compounds, don't proceed with parameterization   \n",
    "\n",
    "                    offmol = topology.get_largest_offmol(offtop)\n",
    "                    offmol.name = polymer_name\n",
    "\n",
    "                    # 3b) Assign partial charges, if not already present\n",
    "                    if not molchargers.has_partial_charges(offmol):\n",
    "                        status_readout.update(status_id, action=f'Assigning partial charges via {charger.CHARGING_METHOD}')\n",
    "                        cmol = charger.charge_molecule(offmol)\n",
    "                        unique_elems = re.findall(HILL_REGEX, cmol.hill_formula) # unique element names in same order as found in Hill formula\n",
    "                    \n",
    "                    # generate tiled lattices as specified\n",
    "                    for max_num_atoms in max_num_atoms_array:\n",
    "                        lattice_str = f'sub_{max_num_atoms}_atoms'\n",
    "                        latt_dir : Path = dop_dir / lattice_str\n",
    "                        latt_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                        int_lattice = generate_uniform_subpopulated_lattice(max_num_atoms, num_atoms_in_mol=cmol.n_atoms)\n",
    "                        r_eff = rdmol_effective_radius(cmol.to_rdkit())\n",
    "                        lattice = int_lattice.linear_transformation(2.0*r_eff*np.eye(3), as_coords=True) # scale integer lattice my effective diameter\n",
    "\n",
    "                        # create tiled version of parameterized topology\n",
    "                        with Timer() as topo_timer:\n",
    "                            status_readout.update(status_id, action=f'Generating tiled {lattice_str} topology')\n",
    "                            tiled_offtop = topology.topology_from_molecule_onto_lattice(cmol, lattice_points=lattice.points, rotate_randomly=True, unique_mol_ids=True)\n",
    "                            latt_top_path = assemble_path(latt_dir, lattice_str, postfix=polymer_name, extension='sdf')\n",
    "                            topology.topology_to_sdf(latt_top_path, tiled_offtop)\n",
    "\n",
    "                            latt_pdb_path = assemble_path(latt_dir, lattice_str, postfix=polymer_name, extension='pdb')\n",
    "                            tiled_offtop.to_file(latt_pdb_path)\n",
    "\n",
    "                        # generate appropriately-sized periodic box size, starting with the tight bounding box for the topology\n",
    "                        top_box_vectors = boxvectors.get_topology_bbox(tiled_offtop) # determine tight box size\n",
    "                        top_box_vectors = boxvectors.pad_box_vectors_uniform(top_box_vectors, exclusion) # apply periodic box (with padding) to Interchange\n",
    "                        top_box_vectors = np.maximum(min_bbox, top_box_vectors) # enusre the box is no smaller than the minimum determined by the cutoff distance\n",
    "\n",
    "                        top_box_vectors_omm = openff_to_openmm(top_box_vectors)\n",
    "                        box_vector_sizes = np.linalg.norm(top_box_vectors_omm, axis=1) * top_box_vectors_omm.unit # rows are each a distinct box vector\n",
    "                        box_vector_dict = {\n",
    "                            f'box_dim_{axis} ({size_quant.unit!s})' : size_quant._value\n",
    "                                for (axis, size_quant) in zip('xyz', box_vector_sizes)\n",
    "                        }\n",
    "\n",
    "                        # create and save Interchange for MD export\n",
    "                        with Timer() as inc_timer:\n",
    "                            status_readout.update(status_id, action=f'Creating {lattice_str} OpenFF Interchange')\n",
    "                            interchange = forcefield.create_interchange(tiled_offtop, charge_from_molecules=[cmol])\n",
    "                            interchange.box = top_box_vectors # apply periodic box to Interchange\n",
    "\n",
    "                            # configure nonbonded in Interchange to have correct cutoff and switching function width\n",
    "                            interchange['vdW'].switch_width = (1.0 if switching_function else 0.0) * angstrom\n",
    "                            interchange['vdW'           ].cutoff = nonbond_cutoff\n",
    "                            interchange['Electrostatics'].cutoff = nonbond_cutoff\n",
    "\n",
    "                        latt_inc_path = assemble_path(latt_dir, lattice_str, postfix=polymer_name, extension='pkl')\n",
    "                        with latt_inc_path.open('wb') as pklfile: # NOTE: pickled files must be read/written in binary mode\n",
    "                            pickle.dump(interchange, pklfile)\n",
    "\n",
    "                        # record information about MD build run to simplfiy resuming, analyzing, and benchmarking structure outputs\n",
    "                        md_build_entry = {\n",
    "                            'mechanism'                : rxn_name,\n",
    "                            'polymer_name'             : polymer_name,\n",
    "                            'exper_density'            : row['Density'],\n",
    "                            'n_atoms_cap'              : lattice_str,\n",
    "                            'lattice_size'             : int_lattice.counts_along_dims_as_str(),\n",
    "                            'num_oligomers'            : lattice.n_points,\n",
    "                            'effective radius'         : r_eff,\n",
    "                            'oligomer_type'            : nmer_name,\n",
    "                            'n_atoms_in_topology'      : tiled_offtop.n_atoms,\n",
    "                            'unique_elems_in_topology' : unique_elems, \n",
    "                            'directory'                : str(latt_dir),\n",
    "                            'topology_path'            : str(latt_top_path),\n",
    "                            'topology_time'            : topo_timer.time_taken,\n",
    "                            'interchange_path'         : str(latt_inc_path),\n",
    "                            'interchange_time'         : inc_timer.time_taken,\n",
    "                        }\n",
    "                        md_build_entry.update(box_vector_dict)\n",
    "                        md_build_records.append(md_build_entry)\n",
    "\n",
    "                        md_build_entry_path = assemble_path(latt_dir, f'{lattice_str}_{nmer_name}_{polymer_name}', postfix='RECORD', extension='json')\n",
    "                        with md_build_entry_path.open('w') as record_file: # also save to disc individually, to allow reconstruction if loop fails haflway through\n",
    "                            json.dump(md_build_entry, record_file, indent=4)\n",
    "                    \n",
    "                num_successful += 1\n",
    "\n",
    "            except Exception as other_error:\n",
    "                failure_record[other_error.__class__.__name__][rxn_name][polymer_name] = str(other_error)\n",
    "            finally:\n",
    "                intra_mech_progress.advance(mech_task_id)\n",
    "                compound_progress.advance(comp_progress_id)\n",
    "                \n",
    "        inter_mech_progress.advance(curr_mechanism_id, advance=1)\n",
    "        sleep(0.1) # needed to give final bar enough time to catch up\n",
    "    compound_readout.update(curr_compound_id, polymer_name=f'Completed! ({num_successful}/{total_compounds} successful)')\n",
    "\n",
    "all_records_path = assemble_path(MASTER_OUT_DIR, 'build_records', extension='csv')\n",
    "md_build_records_table = pd.DataFrame.from_records(md_build_records)\n",
    "md_build_records_table.set_index(['mechanism', 'polymer_name'], inplace=True)\n",
    "md_build_records_table.to_csv(all_records_path)\n",
    "\n",
    "m2p_mismatch_path = assemble_path(MASTER_OUT_DIR, 'm2p_mismatches', extension='json')\n",
    "with m2p_mismatch_path.open('w') as m2p_mismatch_file:\n",
    "    json.dump(m2p_mismatches, m2p_mismatch_file, indent=4)\n",
    "\n",
    "print(failure_record)\n",
    "print(m2p_mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
