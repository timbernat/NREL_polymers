{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The OpenEye Toolkits are found to be installed but not licensed and therefore will not be used.\n",
      "The OpenEye Toolkits require a (free for academics) license, see https://docs.eyesopen.com/toolkits/python/quickstart-python/license.html\n",
      "The OpenEye Toolkits are found to be installed but not licensed and therefore will not be used.\n",
      "The OpenEye Toolkits require a (free for academics) license, see https://docs.eyesopen.com/toolkits/python/quickstart-python/license.html\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52263938d384179a7ca43be578beaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Logging and Shell\n",
    "import logging\n",
    "\n",
    "from polymerist.openfftools.partialcharge import molchargers\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    force=True\n",
    ")\n",
    "\n",
    "## Generic imports\n",
    "from typing import Any, Optional\n",
    "from collections import defaultdict\n",
    "\n",
    "## Numeric imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## File I/O\n",
    "from pathlib import Path\n",
    "import json, pickle\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "\n",
    "from openmm.unit import nanometer, Quantity\n",
    "\n",
    "from openff.toolkit import Molecule, Topology, ForceField\n",
    "from openff.toolkit.utils.exceptions import (\n",
    "    UnassignedChemistryInPDBError,\n",
    "    IncorrectNumConformersWarning,\n",
    ")\n",
    "\n",
    "# Custom Imports\n",
    "from polymerist.genutils.containers import RecursiveDict\n",
    "from polymerist.genutils.fileutils import filetree\n",
    "from polymerist.duration import Duration\n",
    "from polymerist.unitutils.interop import openmm_to_openff\n",
    "\n",
    "from polymerist.maths.greek import GREEK_PREFIXES\n",
    "from polymerist.maths.lattices import generate_int_lattice\n",
    "\n",
    "from polymerist.rdutils.rdprops import copy_rd_props\n",
    "from polymerist.rdutils.rdcoords import tiling\n",
    "from polymerist.rdutils.reactions import reactions, reactors\n",
    "\n",
    "from polymerist.openfftools.partition import partition\n",
    "from polymerist.openfftools import topology, boxvectors, FFDIR\n",
    "from polymerist.monomers import specification, MonomerGroup\n",
    "from polymerist.polymers import building\n",
    "\n",
    "# catch annoying warnings\n",
    "import warnings \n",
    "warnings.catch_warnings(record=True)\n",
    "warnings.filterwarnings('ignore', category=IncorrectNumConformersWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load monomer and rxn data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Paths\n",
    "RAW_DATA_DIR  = Path('monomer_data_raw')\n",
    "FMT_DATA_DIR  = Path('monomer_data_formatted')\n",
    "PROC_DATA_DIR = Path('monomer_data_processed')\n",
    "RXN_FILES_DIR = Path('poly_rxns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data_path = PROC_DATA_DIR / '20231114_polyid_data_density_DP2-6 - 1,2 monomers_FILTERED.csv'\n",
    "# input_data_path = PROC_DATA_DIR / 'nipu_urethanes_FILTERED.csv'\n",
    "# input_data_path = PROC_DATA_DIR / 'monomer_data_MASTER.csv'\n",
    "input_data_path = PROC_DATA_DIR / 'monomer_data_MASTER_dens_vdW.csv'\n",
    "df = pd.read_csv(input_data_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-defined reactions with functional group and name backmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['rxn_name']\n",
    "take_first_n : Optional[int] = None\n",
    "# take_first_n : Optional[int] = 2\n",
    "\n",
    "blacklisted_rxns = ['imide']#, 'vinyl']\n",
    "df = df[df.mechanism.map(lambda s : s not in blacklisted_rxns)]\n",
    "\n",
    "df_grouper = df.groupby(keys)\n",
    "frames_by_mech = { # separate into individual dataframes grouped by reaction mechanism\n",
    "    mech : df_grouper.get_group(mech)\n",
    "        for mech in df_grouper.groups\n",
    "}\n",
    "\n",
    "if take_first_n is not None: # useful for debugging a small subset\n",
    "    frames_by_mech = {\n",
    "        mech : frame.head(take_first_n)\n",
    "            for mech, frame in frames_by_mech.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (RXN_FILES_DIR / 'rxn_groups.json').open('r') as file: # load table of functional group for each reaction\n",
    "    rxn_groups = json.load(file)\n",
    "\n",
    "rxns = {\n",
    "    rxnname : reactions.AnnotatedReaction.from_rxnfile(RXN_FILES_DIR / f'{rxnname}.rxn')\n",
    "        for rxnname in rxn_groups.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-generating monomer fragments and Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and format progress bars to track build status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.progress import Progress\n",
    "from rich.progress import (\n",
    "    BarColumn,\n",
    "    Progress,\n",
    "    SpinnerColumn,\n",
    "    TaskProgressColumn,\n",
    "    TextColumn,\n",
    "    TimeElapsedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "from rich.console import Group\n",
    "from rich.live import Live\n",
    "\n",
    "# status of individual task\n",
    "status_readout = Progress(\n",
    "    'STATUS:',\n",
    "    TextColumn(\n",
    "        '[purple]{task.fields[action]}'\n",
    "    ),\n",
    "    '...'\n",
    ")\n",
    "status_id = status_readout.add_task('[green]Current compound:', action='')\n",
    "\n",
    "# textual display of the name of the curent polymer\n",
    "compound_readout = Progress(\n",
    "    'Current compound:',\n",
    "    TextColumn(\n",
    "        '[blue]{task.fields[polymer_name]}',\n",
    "        justify='right'\n",
    "    )\n",
    ")\n",
    "curr_compound_id  = compound_readout.add_task('[green]Compound:', polymer_name='')\n",
    "\n",
    "# progress over individual compounds (irrespective of mechanism)\n",
    "compound_progress = Progress(\n",
    "    SpinnerColumn(),\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    ")\n",
    "comp_progress_id = compound_progress.add_task('[blue]Unique compound(s)   ', polymer_name='')\n",
    "\n",
    "# progress over distinct classes of mechanism\n",
    "inter_mech_progress = Progress(\n",
    "    SpinnerColumn(),\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    ")\n",
    "curr_mechanism_id = inter_mech_progress.add_task('[blue]Reaction mechanism(s)', start=True, total=len(frames_by_mech))\n",
    "\n",
    "# individual progress bars for compounds within each mechanism\n",
    "intra_mech_progress = Progress(\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    "    'At:',\n",
    "    TimeElapsedColumn(),\n",
    ")\n",
    "total_compounds = 0\n",
    "mech_task_ids = {} # preprocess dataframes by mechanism to determine progress bar layout and task lengths\n",
    "for rxn_name, rxn_df in frames_by_mech.items():\n",
    "    num_compounds = len(rxn_df)\n",
    "    mech_task_ids[rxn_name] = intra_mech_progress.add_task(f'[cyan]{rxn_name}', start=True, total=len(rxn_df))\n",
    "    total_compounds += num_compounds\n",
    "compound_progress.update(curr_compound_id, total=total_compounds)\n",
    "\n",
    "# combine progess readouts into unified live console\n",
    "group = Group(\n",
    "    status_readout,\n",
    "    compound_readout,\n",
    "    compound_progress,\n",
    "    inter_mech_progress,\n",
    "    intra_mech_progress,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from time import sleep, time\n",
    "from polymerist.rdutils.rdtypes import RDMol\n",
    "\n",
    "\n",
    "HILL_REGEX = re.compile(r'([A-Z][a-z]?)[0-9]*?') # break apart hill formula into just unique elements (one captial letter, one or no lowercase letters, any (including none) digits)\n",
    "\n",
    "class Timer:\n",
    "    '''Simple context manager for measuring how long something takes'''\n",
    "    def __init__(self) -> None:\n",
    "        self.start_time = time()\n",
    "        self.time_taken = None\n",
    "\n",
    "    def __enter__(self) -> 'Timer':\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback) -> bool:\n",
    "        self.time_taken = time() - self.start_time\n",
    "        return True\n",
    "\n",
    "def generate_smarts_fragments(reactants_dict : dict[str, RDMol], reactor : reactors.PolymerizationReactor) -> MonomerGroup:\n",
    "    '''Takes a labelled dict of reactant Mols and a PolymerizationReactor object with predefined rxn mechanism\n",
    "    Returns a MonomerGroup containing all fragments enumerated by the provided rxn'''\n",
    "    monogrp = MonomerGroup()\n",
    "    initial_reactants = [reactants for reactants in reactants_dict.values()] # must convert to list to pass to ChemicalReaction\n",
    "    \n",
    "    for dimer, frags in reactor.propagate(initial_reactants):\n",
    "        for assoc_group_name, rdfragment in zip(reactants_dict.keys(), frags):\n",
    "            # generate spec-compliant SMARTS\n",
    "            raw_smiles = Chem.MolToSmiles(rdfragment)\n",
    "            exp_smiles = specification.expanded_SMILES(raw_smiles)\n",
    "            spec_smarts = specification.compliant_mol_SMARTS(exp_smiles)\n",
    "\n",
    "            # record to monomer group\n",
    "            affix = 'TERM' if MonomerGroup.is_terminal(rdfragment) else 'MID'\n",
    "            monogrp.monomers[f'{assoc_group_name}_{affix}'] = [spec_smarts]\n",
    "\n",
    "    return monogrp\n",
    "\n",
    "def topology_from_molecule_onto_lattice(cmol : Molecule, lattice : np.ndarray):\n",
    "    '''Convert a charged OpenFF Molecule into a Topology made up of copies of that Molecule tiled according to a lattice'''\n",
    "    tiled_rdmol = tiling.tile_lattice_with_rdmol(cmol.to_rdkit(), lattice)\n",
    "\n",
    "    tiled_offmols = [] \n",
    "    for mol_id, tiled_mol_copy in enumerate(Chem.GetMolFrags(tiled_rdmol, asMols=True, sanitizeFrags=False)):\n",
    "        copy_rd_props(tiled_rdmol, tiled_mol_copy) # ensure each individual fragment preserves the information of the parent molecule\n",
    "        tiled_offmol = Molecule.from_rdkit(\n",
    "            rdmol=tiled_mol_copy,\n",
    "            allow_undefined_stereo=True,\n",
    "            hydrogens_are_explicit=True\n",
    "        )\n",
    "        for atom in tiled_offmol.atoms:\n",
    "            atom.metadata['residue_number'] = mol_id # this appear to be the mechanism by which Interchange assigns labels to unique molecules (per Daria's request)\n",
    "        tiled_offmols.append(tiled_offmol)\n",
    "\n",
    "    return Topology.from_molecules(tiled_offmols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters for build process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASTER_OUT_DIR = Path('polymer_structures')\n",
    "# MASTER_OUT_DIR = Path('polymer_validation')\n",
    "MASTER_OUT_DIR = Path('polymer_filtered')\n",
    "\n",
    "DOPs : list[int] = [3]\n",
    "charge_method : str = 'Espaloma-AM1-BCC'\n",
    "force_field_name : str = 'openff_unconstrained-2.0.0.offxml' # 'openff-2.0.0.offxml'\n",
    "\n",
    "lattice_sizes : list[np.ndarray] = [\n",
    "    np.array([1, 1, 1]), # just a single molecule in a box\n",
    "    np.array([2, 2, 2]),\n",
    "    np.array([3, 3, 3]),\n",
    "    np.array([5, 5, 5]),\n",
    "]\n",
    "exclusion : Quantity = 0.0 * nanometer \n",
    "nonbond_cutoff : Quantity = 0.9 * nanometer\n",
    "\n",
    "clear_existing           : bool = True#False\n",
    "refragment               : bool = False  \n",
    "repolymerize_pdbs        : bool = False\n",
    "reparameterize           : bool = False\n",
    "reassign_partial_charges : bool = False\n",
    "perform_energy_min       : bool = True\n",
    "\n",
    "# preprocess parameters\n",
    "charger = molchargers.MolCharger.subclass_registry[charge_method]()\n",
    "lattices = {\n",
    "    'x'.join(str(i) for i in lattice_size) : generate_int_lattice(*lattice_size)\n",
    "        for lattice_size in lattice_sizes\n",
    "}\n",
    "forcefield = ForceField(FFDIR / force_field_name)\n",
    "\n",
    "min_box_dim : Quantity = 2 * nonbond_cutoff # should be at least twice the nonbonded cutoff to avoid self-interaction\n",
    "min_bbox = openmm_to_openff(min_box_dim * np.eye(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute build loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ca534b388940a89c4b57a72110031d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/mbuild/compound.py:2829: UserWarning: \n",
       "Performing energy minimization using the Open Babel package. Please refer to the documentation to find the \n",
       "appropriate citations for Open Babel and the UFF force field\n",
       "  warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/mbuild/compound.py:2829: UserWarning: \n",
       "Performing energy minimization using the Open Babel package. Please refer to the documentation to find the \n",
       "appropriate citations for Open Babel and the UFF force field\n",
       "  warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/dgl/heterograph.py:92: DGLWarning: \n",
       "Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
       "  dgl_warning(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/timber/miniconda3/envs/polymerist-env/lib/python3.11/site-packages/dgl/heterograph.py:92: DGLWarning: \n",
       "Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
       "  dgl_warning(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecursiveDict(<class 'polymerist.genutils.containers.RecursiveDict'>, {})\n"
     ]
    }
   ],
   "source": [
    "# create directories\n",
    "MASTER_OUT_DIR.mkdir(exist_ok=True)\n",
    "if clear_existing:\n",
    "    filetree.clear_dir(MASTER_OUT_DIR)\n",
    "\n",
    "# set up data structures for global output\n",
    "frag_registry  = RecursiveDict()\n",
    "failure_record = RecursiveDict()\n",
    "\n",
    "# execute build loop\n",
    "num_successful : int = 0\n",
    "md_build_records : list[dict[str, Any]] = []\n",
    "with Live(group, refresh_per_second=10) as live:\n",
    "    # ensure bars start at 0\n",
    "    for pbar in group.renderables: \n",
    "        for task_id in pbar.task_ids:\n",
    "            pbar.reset(task_id)\n",
    "\n",
    "    # iterate over all distinct chemistries by reaction mechanism\n",
    "    for rxn_name, rxn_df in frames_by_mech.items():\n",
    "        # look up reactive groups and pathway by mechanism\n",
    "        mech_task_id = mech_task_ids[rxn_name]\n",
    "        rxn_pathway  = rxns[rxn_name]\n",
    "        reactor = reactors.PolymerizationReactor(rxn_pathway)\n",
    "        \n",
    "        # initialize output directories\n",
    "        mech_dir : Path = MASTER_OUT_DIR / rxn_name\n",
    "        mech_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        for (i, row) in rxn_df.iterrows():\n",
    "            # 0) load reactants with IUPAC names from chemical table\n",
    "            status_readout.update(status_id, action='Gathering reactants')\n",
    "            named_reactants = {}\n",
    "            for j in range(2):\n",
    "                reactant = Chem.MolFromSmiles(row[f'smiles_monomer_{j}'], sanitize=False)\n",
    "                Chem.SanitizeMol(reactant, sanitizeOps=specification.SANITIZE_AS_KEKULE)\n",
    "                named_reactants[ row[f'IUPAC_name_monomer_{j}'] ] = reactant\n",
    "\n",
    "            # 0a) auto-generate name of the current polymer (this is needed to finish setting up several prereqs viz dirs, progress, etc.) \n",
    "            polymer_name = f'poly({\"-co-\".join(named_reactants.keys())})'.lower() # TODO : make sure this conforms to IUPAC standards for naming (not strictly copolmyers here)\n",
    "            compound_readout.update(curr_compound_id, polymer_name=polymer_name)\n",
    "            frag_registry[rxn_name][i] = polymer_name\n",
    "\n",
    "            chem_dir : Path = mech_dir / polymer_name\n",
    "            chem_dir.mkdir(exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                # 1) use rxn template to polymerize monomers into all possible fragments\n",
    "                frag_path = chem_dir / f'{polymer_name}.json'\n",
    "                if frag_path.exists() and not refragment: # if fragments have already been \n",
    "                    status_readout.update(status_id, action='Loading pre-existing monomer fragments')\n",
    "                    monogrp = MonomerGroup.from_file(frag_path)\n",
    "                else:\n",
    "                    status_readout.update(status_id, action='Generating monomer fragments via reaction mechanism')\n",
    "                    monogrp = generate_smarts_fragments(named_reactants, reactor=reactor)\n",
    "\n",
    "                    status_readout.update(status_id, action='Saving monomer fragments...')\n",
    "                    monogrp.to_file(frag_path)\n",
    "\n",
    "                for dop in DOPs:\n",
    "                    nmer_name = f'{GREEK_PREFIXES[dop]}mer'\n",
    "                    dop_dir : Path = chem_dir / nmer_name\n",
    "                    dop_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                    # 2) Generate PDB file for linear chain from fragments\n",
    "                    pdb_path : Path = dop_dir / f'{polymer_name}.pdb'\n",
    "                    if not pdb_path.exists() or repolymerize_pdbs:\n",
    "                        status_readout.update(status_id, action=f'Generating PDB file (with{\"\" if perform_energy_min else \"out\"} UFF energy minimization)')\n",
    "                        polymer = building.build_linear_polymer(monomers=monogrp, DOP=dop+1, sequence='BA', energy_minimize=perform_energy_min)  # \"BA\" is needed to make term groups align properly, DOP does not account for term group pair (hence the \"+1\")\n",
    "                        building.mbmol_to_openmm_pdb(pdb_path, polymer)\n",
    "\n",
    "                    # 3a) Assign chemical info to PDB system\n",
    "                    param_top_path = dop_dir / f'{polymer_name}.sdf'\n",
    "                    if param_top_path.exists() and not reparameterize:\n",
    "                        status_readout.update(status_id, action='Loading parameterized single-mol Topology')\n",
    "                        offtop = topology.topology_from_sdf(param_top_path)\n",
    "                    else:\n",
    "                        try:\n",
    "                            status_readout.update(status_id, action='Partitioning topology by fragments')\n",
    "                            offtop = Topology.from_pdb(pdb_path, _custom_substructures=monogrp.monomers)\n",
    "                            assert(partition(offtop)) # verify that a partition was possible\n",
    "                            topology.topology_to_sdf(param_top_path, offtop)\n",
    "                        except UnassignedChemistryInPDBError:\n",
    "                            failure_record['No substruct cover'][rxn_name][polymer_name][dop] = monogrp\n",
    "                            continue # skip to next compounds, don't proceed with parameterization   \n",
    "                        except AssertionError:\n",
    "                            failure_record['No substruct partition'][rxn_name][polymer_name][dop] = monogrp\n",
    "                            continue # skip to next compounds, don't proceed with parameterization   \n",
    "\n",
    "                    offmol = topology.get_largest_offmol(offtop)\n",
    "                    offmol.name = polymer_name\n",
    "\n",
    "                    # 3b) Assign partial charges, if not already present\n",
    "                    if not molchargers.has_partial_charges(offmol):\n",
    "                        status_readout.update(status_id, action=f'Assigning partial charges via {charger.CHARGING_METHOD}')\n",
    "                        cmol = charger.charge_molecule(offmol)\n",
    "                    \n",
    "                    # generate tiled lattices as specified\n",
    "                    for lattice_str, lattice in lattices.items(): # NOTE : key that this is done AFTER parameterization to avoid reassigning parameters to a (potentially) much larger Topology\n",
    "                        latt_dir : Path = dop_dir / lattice_str\n",
    "                        latt_dir.mkdir(exist_ok=True)\n",
    "\n",
    "                        # create tiled version of parameterized topology\n",
    "                        with Timer() as topo_timer:\n",
    "                            status_readout.update(status_id, action=f'Generating tiled {lattice_str} topology')\n",
    "                            tiled_offtop = topology_from_molecule_onto_lattice(cmol, lattice=lattice)\n",
    "                            latt_top_path = latt_dir / f'{lattice_str}_{polymer_name}.sdf'\n",
    "                            topology.topology_to_sdf(latt_top_path, tiled_offtop)\n",
    "\n",
    "                        # generate appropriately-sized periodic box size, starting with the tight bounding box for the topology\n",
    "                        top_box_vectors = boxvectors.get_topology_bbox(tiled_offtop) # determine tight box size\n",
    "                        top_box_vectors = boxvectors.pad_box_vectors_uniform(top_box_vectors, exclusion) # apply periodic box (with padding) to Interchange\n",
    "                        top_box_vectors = np.maximum(min_bbox, top_box_vectors) # enusre the box is no smaller than the minimum determined by the cutoff distance\n",
    "\n",
    "                        # create and save Interchange for MD export\n",
    "                        with Timer() as inc_timer:\n",
    "                            status_readout.update(status_id, action=f'Creating {lattice_str} OpenFF Interchange')\n",
    "                            interchange = forcefield.create_interchange(tiled_offtop, charge_from_molecules=[cmol])\n",
    "                            interchange.box = top_box_vectors # apply periodic box to Interchange\n",
    "\n",
    "                        latt_inc_path = latt_dir / f'{lattice_str}_{polymer_name}.pkl'\n",
    "                        with latt_inc_path.open('wb') as pklfile: # NOTE: pickled files must be read/written in binary mode\n",
    "                            pickle.dump(interchange, pklfile)\n",
    "\n",
    "                        # record information about MD build run to simplfiy resuming, analyzing, and benchmarking structure outputs\n",
    "                        md_build_entry = {\n",
    "                            'mechanism'                : rxn_name,\n",
    "                            'polymer_name'             : polymer_name,\n",
    "                            'lattice_size'             : lattice_str,\n",
    "                            'oligomer_type'            : nmer_name,\n",
    "                            'n_atoms_in_topology'      : tiled_offtop.n_atoms,\n",
    "                            'unique_elems_in_topology' : re.findall(HILL_REGEX, cmol.hill_formula), # unique elemtn names in same order as found in Hill formula\n",
    "                            'directory'                : str(latt_dir),\n",
    "                            'topology_path'            : str(latt_top_path),\n",
    "                            'topology_time'            : topo_timer.time_taken,\n",
    "                            'interchange_path'         : str(latt_inc_path),\n",
    "                            'interchange_time'         : inc_timer.time_taken,\n",
    "                        }\n",
    "                        md_build_records.append(md_build_entry)\n",
    "\n",
    "                        md_build_entry_path = latt_dir / f'{lattice_str}_{nmer_name}_{polymer_name}_RECORD.json'\n",
    "                        with md_build_entry_path.open('w') as record_file: # also save to disc individually, to allow reconstruction if loop fails haflway through\n",
    "                            json.dump(md_build_entry, record_file, indent=4)\n",
    "                    \n",
    "                num_successful += 1\n",
    "\n",
    "            except Exception as other_error:\n",
    "                failure_record[other_error.__class__.__name__][rxn_name][polymer_name] = str(other_error)\n",
    "            finally:\n",
    "                intra_mech_progress.advance(mech_task_id)\n",
    "                compound_progress.advance(comp_progress_id)\n",
    "                \n",
    "        inter_mech_progress.advance(curr_mechanism_id, advance=1)\n",
    "        sleep(0.1) # needed to give final bar enough time to catch up\n",
    "    compound_readout.update(curr_compound_id, polymer_name=f'Completed! ({num_successful}/{total_compounds} successful)')\n",
    "\n",
    "all_records_path = MASTER_OUT_DIR / 'build_records.csv'\n",
    "md_build_records_table = pd.DataFrame.from_records(md_build_records)\n",
    "md_build_records_table.set_index(['mechanism', 'polymer_name'], inplace=True)\n",
    "md_build_records_table.to_csv(all_records_path)\n",
    "\n",
    "print(failure_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
