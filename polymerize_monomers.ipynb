{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logging and Shell\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.ERROR,\n",
    "    force=True\n",
    ")\n",
    "\n",
    "## Generic imports\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "## File I/O\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Cheminformatics\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "\n",
    "from openff.toolkit import Topology\n",
    "from openff.toolkit.utils.exceptions import IncorrectNumConformersWarning\n",
    "\n",
    "# Custom Imports\n",
    "from polymerist.maths.greek import GREEK_PREFIXES\n",
    "from polymerist.genutils.containers import RecursiveDict\n",
    "\n",
    "from polymerist.rdutils.reactions import reactions, reactors\n",
    "from polymerist.rdutils import rdkdraw\n",
    "\n",
    "DIM    = 300\n",
    "ASPECT = 3/2\n",
    "rdkdraw.set_rdkdraw_size(DIM, ASPECT)\n",
    "\n",
    "from polymerist.monomers import specification, MonomerGroup\n",
    "from polymerist.residues.partition import partition\n",
    "from polymerist.polymers import building\n",
    "\n",
    "from polymerist.openfftools import topology\n",
    "from polymerist.openfftools.pcharge import MolCharger\n",
    "\n",
    "# catch annoying warnings\n",
    "import warnings \n",
    "warnings.catch_warnings(record=True)\n",
    "warnings.filterwarnings('ignore', category=IncorrectNumConformersWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Paths\n",
    "RAW_DATA_DIR  = Path('monomer_data_raw')\n",
    "FMT_DATA_DIR  = Path('monomer_data_formatted')\n",
    "PROC_DATA_DIR = Path('monomer_data_processed')\n",
    "RXN_FILES_DIR = Path('poly_rxns')\n",
    "\n",
    "PDB_OUT_DIR   = Path('pdb_files')\n",
    "MONO_OUT_DIR  = Path('monomer_fragments')\n",
    "TOPO_OUT_DIR  = Path('Topologies')\n",
    "\n",
    "MONO_OUT_DIR.mkdir(exist_ok=True)\n",
    "PDB_OUT_DIR.mkdir(  exist_ok=True)\n",
    "TOPO_OUT_DIR.mkdir( exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load monomer and rxn data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_data_path = PROC_DATA_DIR / '20231114_polyid_data_density_DP2-6 - 1,2 monomers_FILTERED.csv'\n",
    "# input_data_path = PROC_DATA_DIR / 'nipu_urethanes_FILTERED.csv'\n",
    "input_data_path = PROC_DATA_DIR / 'monomer_data_MASTER.csv'\n",
    "df = pd.read_csv(input_data_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-defined reactions with functional group and name backmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['rxn_name']\n",
    "\n",
    "blacklisted_rxns = ['imide']#, 'vinyl']\n",
    "df = df[df.mechanism.map(lambda s : s not in blacklisted_rxns)]\n",
    "\n",
    "df_grouper = df.groupby(keys)\n",
    "frames = {\n",
    "    mech : df_grouper.get_group(mech)\n",
    "        for mech in df_grouper.groups\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (RXN_FILES_DIR / 'rxn_groups.json').open('r') as file: # load table of functional group for each reaction\n",
    "    rxn_groups = json.load(file)\n",
    "\n",
    "rxns = {\n",
    "    rxnname : reactions.AnnotatedReaction.from_rxnfile(RXN_FILES_DIR / f'{rxnname}.rxn')\n",
    "        for rxnname in rxn_groups.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto-generating monomer fragments and Topologies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up and format progress bars to track build status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from rich.progress import Progress\n",
    "from rich.progress import (\n",
    "    BarColumn,\n",
    "    Progress,\n",
    "    SpinnerColumn,\n",
    "    TaskProgressColumn,\n",
    "    TextColumn,\n",
    "    TimeElapsedColumn,\n",
    "    TimeRemainingColumn,\n",
    ")\n",
    "from rich.console import Group\n",
    "from rich.live import Live\n",
    "\n",
    "# status of individual task\n",
    "status_readout = Progress(\n",
    "    'STATUS:',\n",
    "    TextColumn(\n",
    "        '[purple]{task.fields[action]}'\n",
    "    ),\n",
    "    '...'\n",
    ")\n",
    "status_id = status_readout.add_task('[green]Current compound:', action='')\n",
    "\n",
    "# textual display of the name of the curent polymer\n",
    "compound_readout = Progress(\n",
    "    TextColumn(\n",
    "        'Current compound ({task.completed} / {task.total}):'\n",
    "    ),\n",
    "    TextColumn(\n",
    "        '[blue]{task.fields[polymer_name]}',\n",
    "        justify='right'\n",
    "    )\n",
    ")\n",
    "curr_compound_id  = compound_readout.add_task('[green]Current compound:', polymer_name='')\n",
    "\n",
    "# progress over distinct classes of mechanism\n",
    "overall_progress = Progress(\n",
    "    SpinnerColumn(),\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(\n",
    "        \n",
    "    ),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    "    'At:',\n",
    "    TimeElapsedColumn(),\n",
    ")\n",
    "curr_mechanism_id = overall_progress.add_task('[blue]Reaction mechanism(s)', start=True, total=len(frames))\n",
    "\n",
    "# individual progress bars within each mechanism\n",
    "mechanism_progress = Progress(\n",
    "    \"[progress.description]{task.description}\",\n",
    "    BarColumn(),\n",
    "    TaskProgressColumn(),\n",
    "    TextColumn(\n",
    "        '({task.completed} / {task.total})'\n",
    "    ),\n",
    "    'At:',\n",
    "    TimeElapsedColumn(),\n",
    ")\n",
    "total_compounds = 0\n",
    "mech_task_ids = {} # preprocess dataframes by mechanism to determine progress bar layout and task lengths\n",
    "for rxn_name, rxn_df in frames.items():\n",
    "    num_compounds = len(rxn_df)\n",
    "    mech_task_ids[rxn_name] = mechanism_progress.add_task(f'[cyan]{rxn_name}', start=True, total=len(rxn_df))\n",
    "    total_compounds += num_compounds\n",
    "compound_readout.update(curr_compound_id, total=total_compounds)\n",
    "\n",
    "\n",
    "# combine progess readouts into unified live console\n",
    "group = Group(\n",
    "    status_readout,\n",
    "    compound_readout,\n",
    "    overall_progress,\n",
    "    mechanism_progress,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polymerize all SMILES into fragments, generate PDB topologies, then parameterize chemical and nonbonded info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from openff.toolkit import Molecule, Topology\n",
    "\n",
    "from polymerist.maths.lattices import generate_int_lattice\n",
    "from polymerist.rdutils.rdcoords import tiling\n",
    "from polymerist.rdutils.rdprops import copy_rd_props\n",
    "\n",
    "# Parameters\n",
    "DOP = 3\n",
    "charge_method = 'Espaloma-AM1-BCC'\n",
    "lattice_sizes : list[np.ndarray] = [\n",
    "    np.array([3, 3, 3])\n",
    "]\n",
    "\n",
    "# create directories\n",
    "nmer_name = f'{GREEK_PREFIXES[DOP]}mers'\n",
    "N_MER_DIR_PDB  = PDB_OUT_DIR  / nmer_name \n",
    "N_MER_DIR_TOPO = TOPO_OUT_DIR / nmer_name \n",
    "\n",
    "N_MER_DIR_PDB.mkdir(exist_ok=True)\n",
    "N_MER_DIR_TOPO.mkdir(exist_ok=True)\n",
    "\n",
    "# preprocess parameters\n",
    "charger = MolCharger.subclass_registry[charge_method]()\n",
    "lattices = {\n",
    "    'x'.join(str(i) for i in lattice_size) : generate_int_lattice(*lattice_size)\n",
    "        for lattice_size in lattice_sizes\n",
    "}\n",
    "\n",
    "# set up data structures for global output\n",
    "frag_registry = RecursiveDict()\n",
    "failed_pdb = RecursiveDict()\n",
    "unmatched_pdb_mols = defaultdict(defaultdict)\n",
    "param_cancelled = defaultdict(list)\n",
    "\n",
    "# execute build loop\n",
    "with Live(group, refresh_per_second=10) as live:\n",
    "    # ensure bars start at 0\n",
    "    for pbar in group.renderables: \n",
    "        for task_id in pbar.task_ids:\n",
    "            pbar.reset(task_id)\n",
    "\n",
    "    for rxn_name, rxn_df in frames.items():\n",
    "        # look up reactive groups and pathway by rxn_name\n",
    "        mech_task_id = mech_task_ids[rxn_name]\n",
    "        rxn_pathway = rxns[rxn_name]\n",
    "        reactor = reactors.PolymerizationReactor(rxn_pathway)\n",
    "        \n",
    "        # initialize output directories\n",
    "        mono_dir : Path = MONO_OUT_DIR / rxn_name\n",
    "        mono_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        pdb_dir : Path = N_MER_DIR_PDB / rxn_name\n",
    "        pdb_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        topo_dir_indiv : Path = N_MER_DIR_TOPO / 'individual' / rxn_name\n",
    "        topo_dir_indiv.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        topo_dirs_latt : dict[str, Path] = {} # prepopulate unified directories for each lattice size, as provided\n",
    "        for lattice_str in lattices:\n",
    "            topo_dir_latt = N_MER_DIR_TOPO / lattice_str / rxn_name\n",
    "            topo_dir_latt.mkdir(exist_ok=True, parents=True)\n",
    "            topo_dirs_latt[lattice_str] = topo_dir_latt\n",
    "\n",
    "        for (i, row) in rxn_df.iterrows():\n",
    "        # 0) load reactants with IUPAC names from chemical table\n",
    "            status_readout.update(status_id, action='Gathering reactants')\n",
    "            named_reactants = {}\n",
    "            for j in range(2):\n",
    "                reactant = Chem.MolFromSmiles(row[f'smiles_monomer_{j}'], sanitize=False)\n",
    "                Chem.SanitizeMol(reactant, sanitizeOps=specification.SANITIZE_AS_KEKULE)\n",
    "                named_reactants[ row[f'IUPAC_name_monomer_{j}'] ] = reactant\n",
    "            initial_reactants = [reactants for reactants in named_reactants.values()] # must convert to list to pass to ChemicalReaction\n",
    "\n",
    "            polymer_name = f'poly({\"-co-\".join(named_reactants.keys())})' # TODO : make sure this conforms to IUPAC standards for naming\n",
    "            compound_readout.update(curr_compound_id, polymer_name=polymer_name)\n",
    "            frag_registry[rxn_name][i] = polymer_name\n",
    "\n",
    "        # 1) use rxn template to polymerize monomers into all possible fragments\n",
    "            status_readout.update(status_id, action='Fragmenting via reaction mechanism')\n",
    "            monogrp = MonomerGroup()\n",
    "            for dimer, frags in reactor.propagate(initial_reactants):\n",
    "                for assoc_group_name, rdfragment in zip(named_reactants.keys(), frags):\n",
    "                    # generate spec-compliant SMARTS\n",
    "                    raw_smiles = Chem.MolToSmiles(rdfragment)\n",
    "                    exp_smiles = specification.expanded_SMILES(raw_smiles)\n",
    "                    spec_smarts = specification.compliant_mol_SMARTS(exp_smiles)\n",
    "\n",
    "                    # record to monomer group\n",
    "                    affix = 'TERM' if MonomerGroup.is_terminal(rdfragment) else 'MID'\n",
    "                    monogrp.monomers[f'{assoc_group_name}_{affix}'] = [spec_smarts]\n",
    "\n",
    "            status_readout.update(status_id, action='Saving monomer fragments...')\n",
    "            monogrp.to_file(mono_dir / f'{polymer_name}.json')\n",
    "\n",
    "        # 2) generate PDB file from fragments\n",
    "            status_readout.update(status_id, action='Generating PDB file')\n",
    "            try:\n",
    "                polymer = building.build_linear_polymer(monomers=monogrp, DOP=DOP, sequence='AB')  \n",
    "                mol_pdb_path = pdb_dir / f'{polymer_name}.pdb'\n",
    "                building.mbmol_to_openmm_pdb(mol_pdb_path, polymer)\n",
    "            except Exception as e:\n",
    "                failed_pdb[DOP][rxn_name][e.__class__.__name__][polymer_name] = monogrp\n",
    "                continue # skip to next compounds, don't proceed with parameterization\n",
    "\n",
    "        # 3) Parameterize topology and generate SDF \n",
    "            try:\n",
    "                status_readout.update(status_id, action='Partitioning topology by fragments')\n",
    "                offtop = Topology.from_pdb(mol_pdb_path, _custom_substructures=monogrp.monomers)\n",
    "                was_partitioned = partition(offtop)\n",
    "                assert(was_partitioned)\n",
    "\n",
    "                status_readout.update(status_id, action='Assigning partial charges')\n",
    "                offmol = topology.get_largest_offmol(offtop)\n",
    "                offmol.name = polymer_name\n",
    "                cmol = charger.charge_molecule(offmol)\n",
    "\n",
    "                status_readout.update(status_id, action='Saving individual parameterized topology to SDF')\n",
    "                offtop = cmol.to_topology()\n",
    "                sdf_path = topo_dir_indiv / f'{polymer_name}.sdf'\n",
    "                topology.topology_to_sdf(sdf_path, offtop)\n",
    "\n",
    "                # also generate tiled lattices if specified\n",
    "                for lattice_str, lattice in lattices.items():\n",
    "                    status_readout.update(status_id, action=f'Generating tiled {lattice_str} topology')\n",
    "                    tiled_rdmol = tiling.tile_lattice_with_rdmol(cmol.to_rdkit(), lattice)\n",
    "\n",
    "                    tiled_offmols = [] \n",
    "                    for tiled_mol_copy in Chem.GetMolFrags(tiled_rdmol, asMols=True, sanitizeFrags=False):\n",
    "                        copy_rd_props(tiled_rdmol, tiled_mol_copy) # ensure each individual fragment preserves the information of the parent molecule\n",
    "                        tiled_offmols.append(\n",
    "                            Molecule.from_rdkit(\n",
    "                                rdmol=tiled_mol_copy,\n",
    "                                allow_undefined_stereo=True,\n",
    "                                hydrogens_are_explicit=True\n",
    "                            )\n",
    "                        )\n",
    "                    tiled_offtop = Topology.from_molecules(tiled_offmols)\n",
    "\n",
    "                    status_readout.update(status_id, action=f'Saving {lattice_str} parameterized topology to SDF')\n",
    "                    sdf_path_latt = topo_dir_latt / f'{polymer_name}.sdf'\n",
    "                    topology.topology_to_sdf(sdf_path_latt, tiled_offtop)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f'{polymer_name} : {e}')\n",
    "                unmatched_pdb_mols[str(e)][rxn_name] = polymer_name\n",
    "            finally:\n",
    "                mechanism_progress.advance(mech_task_id)\n",
    "                compound_readout.advance(curr_compound_id)\n",
    "            \n",
    "        overall_progress.advance(curr_mechanism_id, advance=1)\n",
    "    \n",
    "    # Ensure readout are current at end of process\n",
    "    compound_readout.update(curr_compound_id, polymer_name='Completed!')\n",
    "    sleep(0.1) # needed to give final bar enough time to catch up\n",
    "\n",
    "# global output after processing\n",
    "with (MONO_OUT_DIR / 'dataset_backmap.json').open('w') as file:\n",
    "    json.dump(frag_registry, file, indent=4)\n",
    "\n",
    "print(failed_pdb)\n",
    "print(param_cancelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openff-dev-updated",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
